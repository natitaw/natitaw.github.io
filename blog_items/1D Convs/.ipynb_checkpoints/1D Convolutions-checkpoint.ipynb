{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do Convolutions Work for a 1D Signal?\n",
    "\n",
    "<p>Convolutions have become very popular in recent years, especially in the area of image processing. This is due to their ability to handle raw data from sensors. There is a lot of information available regarding neural nets involving 2D convolutions but not so much when it comes to 1D convolutions. It is my hope to contribute to that gap in this notebook/article.</p>\n",
    "\n",
    "\n",
    "\n",
    "## How are 1D Convolutions Different From 2D Convolutions? \n",
    "\n",
    "- In a normal matrix operation, a map M is applied on input data x. This is shown in the image below.\n",
    "    - On the left you see a big box of height m and width n, this represent the matrix Map, on the right you see the input data which has the same height as the map. When the map is applied on the input, it projects it according to the information encoded in the map\n",
    "\n",
    "    <img src=\"normal_oper.png\" wialign=\"center\"/>\n",
    "\n",
    "\n",
    "- The convolution operation is similar to a normal matrix operation in a sense that it is also a kind of projection of the input data onto a differnt representation. Here, instead of a matrix map, kernels are used to create the projection.\n",
    "    - Essentially, the operation involves computation of dot products as the kernel (a sort of filter) moves across the data\n",
    "    - On the left you see the kernles stacked on eachother (given in different colors), on the right you see the result of convolution.\n",
    "        - There are 3 kernels and they are applied on the input **n**, resulting in 3 different matrices  \n",
    "        <img src=\"kernel_conv.png\" wialign=\"center\"/>\n",
    "\n",
    "    - The kernel can also be applied on a multi-channel data like in the case of a stereo input. This is shown in the image below.\n",
    "        - Here the kernel will slide downwards (only in one direction, hence 1D convolution) resulting in convoluted data shown on the right\n",
    "            - In this case, the convolution results in a scalar product. This is shown with mini-boxes on the right side of the image below\n",
    "        <img src=\"1d_conv.png\" wialign=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the usual suspects\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stereo Channel Input\n",
    "\n",
    "- Consider a stereo input which has two 1D channels (Left and Right). The following convolutional architecture would be suitable to handle such input.\n",
    "    - Input channels = 2\n",
    "    - Output channels = 16\n",
    "        - This means 16 kernels are applied to generate 16 outputs\n",
    "    - Kernel size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture\n",
      "\t Conv1d(2, 16, kernel_size=(3,), stride=(1,))\n",
      "\n",
      "Weights\n",
      "\t torch.Size([16, 2, 3])\n",
      "\n",
      "Bias\n",
      "\t torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# 16 channels\n",
    "# 2 channels\n",
    "# 3 length\n",
    "\n",
    "conv = nn.Conv1d(2, 16, 3)\n",
    "print('Architecture\\n\\t',conv)\n",
    "\n",
    "print('\\nWeights\\n\\t', conv.weight.size())\n",
    "\n",
    "\n",
    "print('\\nBias\\n\\t',conv.bias.size())\n",
    "# 1 bias per channel so 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 1D Convolutional Layer\n",
    "\n",
    "- The 1D CNN architecture is now able to process two channel sound system\n",
    "- Note that whenever a signal is convolved, the length of the data will reduce by the kernel number minus one \n",
    "    - len(data) after convolution = len(data)_before - (k-1)\n",
    "    - In this case, there are 64 samples for each channel so after convolution, there will be 62 samples (64 - (3 - 1) = 62)\n",
    "    \n",
    "- The data needs to be padded such that the data doesn't shrink too much\n",
    "- Stride -> how much you move the kernel\n",
    "- Batches -> how many signals you are using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  torch.Size([16])\n",
      "Output:  torch.Size([1, 16, 62])\n"
     ]
    }
   ],
   "source": [
    "# Generate random data\n",
    "# 1 signal, 2 channels, 64 samples\n",
    "x = torch.randn(1, 2, 64)\n",
    "\n",
    "print('Bias: ', conv.bias.size())\n",
    "print('Output: ', conv(x).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output above shows a reduction of 2 points in the input data x\n",
    "- We can use the automatic gradient tool of PyTorch in order to calculate and keep track of gradients\n",
    "- PyTorch has an automatic funciton **grad_fn** that handles differentiation of tensors\n",
    "- It works as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Lets use a 2x2 tensor with gradient\n",
    "\n",
    "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the argument **requires_grad** is set to **True**, PyTorch will automatically keep track of gradients involving the given variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function:  <SubBackward0 object at 0x7fa7c99f88d0>\n",
      "\n",
      "<AccumulateGrad object at 0x7fa7c99f8d10>\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor([[ 3.,  0.],\n",
      "        [ 3., 12.]], grad_fn=<MulBackward0>)\n",
      "tensor(4.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# perform some operation\n",
    "y = x - 2\n",
    "\n",
    "print('Gradient function: ',y.grad_fn)\n",
    "print()\n",
    "print(y.grad_fn.next_functions[0][0])\n",
    "print(y.grad_fn.next_functions[0][0].variable) # the original tensor\n",
    "\n",
    "# Do another operation on y\n",
    "z = y * y * 3\n",
    "a = z.mean()\n",
    "\n",
    "print(z)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using torchviz to visualize operation done on **a**\n",
    "\n",
    "- torchviz is a useful tool that we can use to visualize operations done on a given variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"106pt\" height=\"271pt\"\n",
       " viewBox=\"0.00 0.00 106.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 102,-267 102,4 -4,4\"/>\n",
       "<!-- 140358618941904 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140358618941904</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"98,-21 0,-21 0,0 98,0 98,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140358618969936 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140358618969936</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94.5,-78 3.5,-78 3.5,-57 94.5,-57 94.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140358618969936&#45;&gt;140358618941904 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140358618969936&#45;&gt;140358618941904</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49,-56.92C49,-49.91 49,-40.14 49,-31.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.5,-31.34 49,-21.34 45.5,-31.34 52.5,-31.34\"/>\n",
       "</g>\n",
       "<!-- 140358577225360 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140358577225360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94.5,-135 3.5,-135 3.5,-114 94.5,-114 94.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140358577225360&#45;&gt;140358618969936 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140358577225360&#45;&gt;140358618969936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49,-113.92C49,-106.91 49,-97.14 49,-88.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.5,-88.34 49,-78.34 45.5,-88.34 52.5,-88.34\"/>\n",
       "</g>\n",
       "<!-- 140358620304912 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140358620304912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-192 4,-192 4,-171 94,-171 94,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140358620304912&#45;&gt;140358577225360 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140358620304912&#45;&gt;140358577225360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M43.73,-170.92C42.35,-163.91 41.94,-154.14 42.48,-145.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.98,-145.68 43.68,-135.34 39.03,-144.86 45.98,-145.68\"/>\n",
       "</g>\n",
       "<!-- 140358620304912&#45;&gt;140358577225360 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140358620304912&#45;&gt;140358577225360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.27,-170.92C55.65,-163.91 56.06,-154.14 55.52,-145.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.97,-144.86 54.32,-135.34 52.02,-145.68 58.97,-144.86\"/>\n",
       "</g>\n",
       "<!-- 140358620367632 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140358620367632</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"76,-263 22,-263 22,-228 76,-228 76,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 140358620367632&#45;&gt;140358620304912 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140358620367632&#45;&gt;140358620304912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49,-227.89C49,-219.99 49,-210.5 49,-202.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.5,-202.02 49,-192.02 45.5,-202.02 52.5,-202.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa7c99f88d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing backpropagation.\n",
    "- This computes gradients to be used for training neural nets with gradient descent\n",
    "\n",
    "- Lets now perform some operations on x and calculate its gradient later\n",
    "    <img src=\"derivative.png\" wialign=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor([[-1.5000,  0.0000],\n",
      "        [ 1.5000,  3.0000]])\n"
     ]
    }
   ],
   "source": [
    "# compute gradients by using backward()\n",
    "a.backward()\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-400.3267, 1547.3759,  526.9937], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1D tenosr with 3 items\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x \n",
    "i = 0\n",
    "# double until the norm of y is under 1000\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    i += 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
      "The number of iterations is given by 11 ==  11\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)\n",
    "print(f'The number of iterations is given by {int(np.log(x.grad[1])/ np.log(2))} == ',i)\n",
    "\n",
    "# 2^i  == x.grad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "x = torch.arange(1., n + 1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "\n",
    "z = w @ x # @ operator is the scalar product\n",
    "z.backward()\n",
    "print(x.grad, w.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError!! ->\n",
      "element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1., n + 1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = w @ x \n",
    "try:\n",
    "    z.backward()\n",
    "except RuntimeError as e:\n",
    "    print('RuntimeError!! ->')\n",
    "    print(e)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
